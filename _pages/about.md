---
layout: about
permalink: /
nav: true
nav_order: 1

profile:
  align: right
  image: prof_pic_zj.jpg
  image_circular: true # ÊòØÂê¶Ë£ÅÂâ™ÊàêÂúÜÂΩ¢Â§¥ÂÉè
  more_info: >
    <p>Edmonton, Alberta, Canada</p>

selected_papers: false
social: true

announcements:
  enabled: false
  scrollable: true
  limit: 5

latest_posts:
  enabled: false
  scrollable: true
  limit: 3
---

<style>
.profile {
  margin-top: -90px !important;
}

.profile-social {
  text-align: center;
}

.profile-social a {
  display: inline-block;
  margin: 0 8px;
  font-size: 1.2em;
  transition: all 0.3s ease;
}

.profile-social a:hover {
  transform: translateY(-2px);
}

/* ‰∏∫‰∏çÂêåÁ§æ‰∫§Âπ≥Âè∞ËÆæÁΩÆÂìÅÁâåËâ≤ÂΩ© */
.profile-social a[title="email"] {
  color: #EA4335;
}

.profile-social a[title="GitHub"] {
  color: #333;
}

.profile-social a[title="LinkedIn"] {
  color: #0077B5;
}

.profile-social a[title="Google Scholar"] {
  color: #4285F4;
}

.profile-social a:hover {
  opacity: 0.8;
}

.profile-social i {
  width: 20px;
  text-align: center;
}

/* Â¢ûÂä†Ê†áÈ¢ò‰πãÈó¥ÁöÑÈó¥Ë∑ù */
h2 {
  margin-top: 2.5rem !important;
  margin-bottom: 1.5rem !important;
}

h3 {
  margin-top: 2rem !important;
  margin-bottom: 1rem !important;
}

/* ‰∏∫Á¨¨‰∏Ä‰∏™h2Ê†áÈ¢òÂáèÂ∞ë‰∏äËæπË∑ù */
h2:first-of-type {
  margin-top: 1.5rem !important;
}
</style>

I am a Ph.D. student at **China University of Geosciences**, advised by <a href="http://grzy.cug.edu.cn/xuchi/zh_CN/index.htm" target="_blank"><b>Prof. Chi Xu</b></a>. I am also a visiting Ph.D. student in <a href="https://vision-and-learning-lab-ualberta.github.io/" target="_blank"><b>Vision and Learning Lab</b></a> at the **University of Alberta**, supervised by <a href="https://www.ece.ualberta.ca/~lcheng5/" target="_blank"><b>Prof. Li Cheng</b></a>.

- 3D Computer Vision & Hand‚ÄìObject Interaction (HOI)
- Physics-aware Perception & Contact/Force Prediction
- Robotics Grasping

A complete list is available on the [Google Scholar](/publications/) page. Selected works are highlighted below.

<div class="row mb-4">
     <div class="col-md-6">
       <img src="{{ site.baseurl }}/assets/img/project/2023-TMM.png" alt="Realistic Depth Image Synthesis for 3D Hand Pose Estimation" class="img-fluid rounded shadow-sm">
     </div>
     <div class="col-md-6">
         <strong>Jun Zhou</strong>, Chi Xu, Yuting Ge, Li Cheng. <a href="https://doi.org/10.1109/TMM.2023.3330522" target="_blank">Realistic Depth Image Synthesis for 3D Hand Pose Estimation</a>. <em>IEEE Transactions on Multimedia</em>, 2024
       </div>
   </div>

<div class="row mb-4">
     <div class="col-md-6">
       <img src="{{ site.baseurl }}/assets/img/project/2025-TMM.png" alt="Hand Gesture Recognition From an Open-Set Perspective" class="img-fluid rounded shadow-sm">
     </div>
            <div class="col-md-6">
         <strong>Jun Zhou</strong>, Chi Xu, Li Cheng. <a href="https://doi.org/10.1109/TMM.2025.3535363" target="_blank">Hand Gesture Recognition From an Open-Set Perspective</a>. <em>IEEE Transactions on Multimedia</em>, 2025
       </div>
   </div>

<div class="row mb-4">
     <div class="col-md-6">
       <img src="{{ site.baseurl }}/assets/img/project/2020-Sensors.png" alt="Robust 3D Hand Detection from a Single RGB-D Image" class="img-fluid rounded shadow-sm">
     </div>
            <div class="col-md-6">
         Chi Xu, <strong>Jun Zhou</strong>, Wei Cai, Yuxin Jiang, Yuxin Li, Yuxin Liu. <a href="https://doi.org/10.3390/s20216360" target="_blank">Robust 3D Hand Detection from a Single RGB-D Image in Unconstrained Environments</a>. <em>Sensors</em>, 2020
       </div>
   </div>

- Placed 2nd in <a href="https://competitions.codalab.org/competitions/20913#results" target="_blank"><b>HANDS19 challenge task</b></a> (ECCV2020 Workshop on Observing and Understanding Hands in Action)

**Reviewer:**

- IEEE Transactions on Multimedia (TMM)
- International Joint Conference on Artificial Intelligence (IJCAI) 2025
- Association for the Advancement of Artificial Intelligence (AAAI) 2026

- C++ Programming, 2019
- C++ Programming, 2020
<!-- ## üì¢ News
See the [News](/news/) page for updates.   -->
